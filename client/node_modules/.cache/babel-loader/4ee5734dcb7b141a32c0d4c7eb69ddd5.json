{"ast":null,"code":"/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nconst {\n  Token\n} = require('./Token');\n\nconst Lexer = require('./Lexer');\n\nconst {\n  Interval\n} = require('./IntervalSet'); // this is just to keep meaningful parameter types to Parser\n\n\nclass TokenStream {}\n/**\n * This implementation of {@link TokenStream} loads tokens from a\n * {@link TokenSource} on-demand, and places the tokens in a buffer to provide\n * access to any previous token by index.\n *\n * <p>\n * This token stream ignores the value of {@link Token//getChannel}. If your\n * parser requires the token stream filter tokens to only those on a particular\n * channel, such as {@link Token//DEFAULT_CHANNEL} or\n * {@link Token//HIDDEN_CHANNEL}, use a filtering token stream such a\n * {@link CommonTokenStream}.</p>\n */\n\n\nclass BufferedTokenStream extends TokenStream {\n  constructor(tokenSource) {\n    super(); // The {@link TokenSource} from which tokens for this stream are fetched.\n\n    this.tokenSource = tokenSource;\n    /**\n     * A collection of all tokens fetched from the token source. The list is\n     * considered a complete view of the input once {@link //fetchedEOF} is set\n     * to {@code true}.\n     */\n\n    this.tokens = [];\n    /**\n     * The index into {@link //tokens} of the current token (next token to\n     * {@link //consume}). {@link //tokens}{@code [}{@link //p}{@code ]} should\n     * be\n     * {@link //LT LT(1)}.\n     *\n     * <p>This field is set to -1 when the stream is first constructed or when\n     * {@link //setTokenSource} is called, indicating that the first token has\n     * not yet been fetched from the token source. For additional information,\n     * see the documentation of {@link IntStream} for a description of\n     * Initializing Methods.</p>\n     */\n\n    this.index = -1;\n    /**\n     * Indicates whether the {@link Token//EOF} token has been fetched from\n     * {@link //tokenSource} and added to {@link //tokens}. This field improves\n     * performance for the following cases:\n     *\n     * <ul>\n     * <li>{@link //consume}: The lookahead check in {@link //consume} to\n     * prevent\n     * consuming the EOF symbol is optimized by checking the values of\n     * {@link //fetchedEOF} and {@link //p} instead of calling {@link\n     * //LA}.</li>\n     * <li>{@link //fetch}: The check to prevent adding multiple EOF symbols\n     * into\n     * {@link //tokens} is trivial with this field.</li>\n     * <ul>\n     */\n\n    this.fetchedEOF = false;\n  }\n\n  mark() {\n    return 0;\n  }\n\n  release(marker) {// no resources to release\n  }\n\n  reset() {\n    this.seek(0);\n  }\n\n  seek(index) {\n    this.lazyInit();\n    this.index = this.adjustSeekIndex(index);\n  }\n\n  get(index) {\n    this.lazyInit();\n    return this.tokens[index];\n  }\n\n  consume() {\n    let skipEofCheck = false;\n\n    if (this.index >= 0) {\n      if (this.fetchedEOF) {\n        // the last token in tokens is EOF. skip check if p indexes any\n        // fetched token except the last.\n        skipEofCheck = this.index < this.tokens.length - 1;\n      } else {\n        // no EOF token in tokens. skip check if p indexes a fetched token.\n        skipEofCheck = this.index < this.tokens.length;\n      }\n    } else {\n      // not yet initialized\n      skipEofCheck = false;\n    }\n\n    if (!skipEofCheck && this.LA(1) === Token.EOF) {\n      throw \"cannot consume EOF\";\n    }\n\n    if (this.sync(this.index + 1)) {\n      this.index = this.adjustSeekIndex(this.index + 1);\n    }\n  }\n  /**\n   * Make sure index {@code i} in tokens has a token.\n   *\n   * @return {Boolean} {@code true} if a token is located at index {@code i}, otherwise\n   * {@code false}.\n   * @see //get(int i)\n   */\n\n\n  sync(i) {\n    const n = i - this.tokens.length + 1; // how many more elements we need?\n\n    if (n > 0) {\n      const fetched = this.fetch(n);\n      return fetched >= n;\n    }\n\n    return true;\n  }\n  /**\n   * Add {@code n} elements to buffer.\n   *\n   * @return {Number} The actual number of elements added to the buffer.\n   */\n\n\n  fetch(n) {\n    if (this.fetchedEOF) {\n      return 0;\n    }\n\n    for (let i = 0; i < n; i++) {\n      const t = this.tokenSource.nextToken();\n      t.tokenIndex = this.tokens.length;\n      this.tokens.push(t);\n\n      if (t.type === Token.EOF) {\n        this.fetchedEOF = true;\n        return i + 1;\n      }\n    }\n\n    return n;\n  } // Get all tokens from start..stop inclusively///\n\n\n  getTokens(start, stop, types) {\n    if (types === undefined) {\n      types = null;\n    }\n\n    if (start < 0 || stop < 0) {\n      return null;\n    }\n\n    this.lazyInit();\n    const subset = [];\n\n    if (stop >= this.tokens.length) {\n      stop = this.tokens.length - 1;\n    }\n\n    for (let i = start; i < stop; i++) {\n      const t = this.tokens[i];\n\n      if (t.type === Token.EOF) {\n        break;\n      }\n\n      if (types === null || types.contains(t.type)) {\n        subset.push(t);\n      }\n    }\n\n    return subset;\n  }\n\n  LA(i) {\n    return this.LT(i).type;\n  }\n\n  LB(k) {\n    if (this.index - k < 0) {\n      return null;\n    }\n\n    return this.tokens[this.index - k];\n  }\n\n  LT(k) {\n    this.lazyInit();\n\n    if (k === 0) {\n      return null;\n    }\n\n    if (k < 0) {\n      return this.LB(-k);\n    }\n\n    const i = this.index + k - 1;\n    this.sync(i);\n\n    if (i >= this.tokens.length) {\n      // return EOF token\n      // EOF must be last token\n      return this.tokens[this.tokens.length - 1];\n    }\n\n    return this.tokens[i];\n  }\n  /**\n   * Allowed derived classes to modify the behavior of operations which change\n   * the current stream position by adjusting the target token index of a seek\n   * operation. The default implementation simply returns {@code i}. If an\n   * exception is thrown in this method, the current stream index should not be\n   * changed.\n   *\n   * <p>For example, {@link CommonTokenStream} overrides this method to ensure\n   * that\n   * the seek target is always an on-channel token.</p>\n   *\n   * @param {Number} i The target token index.\n   * @return {Number} The adjusted target token index.\n   */\n\n\n  adjustSeekIndex(i) {\n    return i;\n  }\n\n  lazyInit() {\n    if (this.index === -1) {\n      this.setup();\n    }\n  }\n\n  setup() {\n    this.sync(0);\n    this.index = this.adjustSeekIndex(0);\n  } // Reset this token stream by setting its token source.///\n\n\n  setTokenSource(tokenSource) {\n    this.tokenSource = tokenSource;\n    this.tokens = [];\n    this.index = -1;\n    this.fetchedEOF = false;\n  }\n  /**\n   * Given a starting index, return the index of the next token on channel.\n   * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n   * on channel between i and EOF.\n   */\n\n\n  nextTokenOnChannel(i, channel) {\n    this.sync(i);\n\n    if (i >= this.tokens.length) {\n      return -1;\n    }\n\n    let token = this.tokens[i];\n\n    while (token.channel !== this.channel) {\n      if (token.type === Token.EOF) {\n        return -1;\n      }\n\n      i += 1;\n      this.sync(i);\n      token = this.tokens[i];\n    }\n\n    return i;\n  }\n  /**\n   * Given a starting index, return the index of the previous token on channel.\n   * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n   * on channel between i and 0.\n   */\n\n\n  previousTokenOnChannel(i, channel) {\n    while (i >= 0 && this.tokens[i].channel !== channel) {\n      i -= 1;\n    }\n\n    return i;\n  }\n  /**\n   * Collect all tokens on specified channel to the right of\n   * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or\n   * EOF. If channel is -1, find any non default channel token.\n   */\n\n\n  getHiddenTokensToRight(tokenIndex, channel) {\n    if (channel === undefined) {\n      channel = -1;\n    }\n\n    this.lazyInit();\n\n    if (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n      throw \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n    }\n\n    const nextOnChannel = this.nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n    const from_ = tokenIndex + 1; // if none onchannel to right, nextOnChannel=-1 so set to = last token\n\n    const to = nextOnChannel === -1 ? this.tokens.length - 1 : nextOnChannel;\n    return this.filterForChannel(from_, to, channel);\n  }\n  /**\n   * Collect all tokens on specified channel to the left of\n   * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.\n   * If channel is -1, find any non default channel token.\n   */\n\n\n  getHiddenTokensToLeft(tokenIndex, channel) {\n    if (channel === undefined) {\n      channel = -1;\n    }\n\n    this.lazyInit();\n\n    if (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n      throw \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n    }\n\n    const prevOnChannel = this.previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n\n    if (prevOnChannel === tokenIndex - 1) {\n      return null;\n    } // if none on channel to left, prevOnChannel=-1 then from=0\n\n\n    const from_ = prevOnChannel + 1;\n    const to = tokenIndex - 1;\n    return this.filterForChannel(from_, to, channel);\n  }\n\n  filterForChannel(left, right, channel) {\n    const hidden = [];\n\n    for (let i = left; i < right + 1; i++) {\n      const t = this.tokens[i];\n\n      if (channel === -1) {\n        if (t.channel !== Lexer.DEFAULT_TOKEN_CHANNEL) {\n          hidden.push(t);\n        }\n      } else if (t.channel === channel) {\n        hidden.push(t);\n      }\n    }\n\n    if (hidden.length === 0) {\n      return null;\n    }\n\n    return hidden;\n  }\n\n  getSourceName() {\n    return this.tokenSource.getSourceName();\n  } // Get the text of all tokens in this buffer.///\n\n\n  getText(interval) {\n    this.lazyInit();\n    this.fill();\n\n    if (interval === undefined || interval === null) {\n      interval = new Interval(0, this.tokens.length - 1);\n    }\n\n    let start = interval.start;\n\n    if (start instanceof Token) {\n      start = start.tokenIndex;\n    }\n\n    let stop = interval.stop;\n\n    if (stop instanceof Token) {\n      stop = stop.tokenIndex;\n    }\n\n    if (start === null || stop === null || start < 0 || stop < 0) {\n      return \"\";\n    }\n\n    if (stop >= this.tokens.length) {\n      stop = this.tokens.length - 1;\n    }\n\n    let s = \"\";\n\n    for (let i = start; i < stop + 1; i++) {\n      const t = this.tokens[i];\n\n      if (t.type === Token.EOF) {\n        break;\n      }\n\n      s = s + t.text;\n    }\n\n    return s;\n  } // Get all tokens from lexer until EOF///\n\n\n  fill() {\n    this.lazyInit();\n\n    while (this.fetch(1000) === 1000) {\n      continue;\n    }\n  }\n\n}\n\nmodule.exports = BufferedTokenStream;","map":{"version":3,"sources":["/home/mario/Desktop/ChessLion/client/node_modules/antlr4/src/antlr4/BufferedTokenStream.js"],"names":["Token","require","Lexer","Interval","TokenStream","BufferedTokenStream","constructor","tokenSource","tokens","index","fetchedEOF","mark","release","marker","reset","seek","lazyInit","adjustSeekIndex","get","consume","skipEofCheck","length","LA","EOF","sync","i","n","fetched","fetch","t","nextToken","tokenIndex","push","type","getTokens","start","stop","types","undefined","subset","contains","LT","LB","k","setup","setTokenSource","nextTokenOnChannel","channel","token","previousTokenOnChannel","getHiddenTokensToRight","nextOnChannel","DEFAULT_TOKEN_CHANNEL","from_","to","filterForChannel","getHiddenTokensToLeft","prevOnChannel","left","right","hidden","getSourceName","getText","interval","fill","s","text","module","exports"],"mappings":"AAAA;AACA;AACA;AACA;AAEA,MAAM;AAACA,EAAAA;AAAD,IAAUC,OAAO,CAAC,SAAD,CAAvB;;AACA,MAAMC,KAAK,GAAGD,OAAO,CAAC,SAAD,CAArB;;AACA,MAAM;AAACE,EAAAA;AAAD,IAAaF,OAAO,CAAC,eAAD,CAA1B,C,CAEA;;;AACA,MAAMG,WAAN,CAAkB;AAElB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,MAAMC,mBAAN,SAAkCD,WAAlC,CAA8C;AAC7CE,EAAAA,WAAW,CAACC,WAAD,EAAc;AAExB,YAFwB,CAGxB;;AACA,SAAKA,WAAL,GAAmBA,WAAnB;AACA;AACF;AACA;AACA;AACA;;AACE,SAAKC,MAAL,GAAc,EAAd;AAEA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACE,SAAKC,KAAL,GAAa,CAAC,CAAd;AAEA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACE,SAAKC,UAAL,GAAkB,KAAlB;AACA;;AAEDC,EAAAA,IAAI,GAAG;AACN,WAAO,CAAP;AACA;;AAEDC,EAAAA,OAAO,CAACC,MAAD,EAAS,CACf;AACA;;AAEDC,EAAAA,KAAK,GAAG;AACP,SAAKC,IAAL,CAAU,CAAV;AACA;;AAEDA,EAAAA,IAAI,CAACN,KAAD,EAAQ;AACX,SAAKO,QAAL;AACA,SAAKP,KAAL,GAAa,KAAKQ,eAAL,CAAqBR,KAArB,CAAb;AACA;;AAEDS,EAAAA,GAAG,CAACT,KAAD,EAAQ;AACV,SAAKO,QAAL;AACA,WAAO,KAAKR,MAAL,CAAYC,KAAZ,CAAP;AACA;;AAEDU,EAAAA,OAAO,GAAG;AACT,QAAIC,YAAY,GAAG,KAAnB;;AACA,QAAI,KAAKX,KAAL,IAAc,CAAlB,EAAqB;AACpB,UAAI,KAAKC,UAAT,EAAqB;AACpB;AACA;AACAU,QAAAA,YAAY,GAAG,KAAKX,KAAL,GAAa,KAAKD,MAAL,CAAYa,MAAZ,GAAqB,CAAjD;AACA,OAJD,MAIO;AACN;AACAD,QAAAA,YAAY,GAAG,KAAKX,KAAL,GAAa,KAAKD,MAAL,CAAYa,MAAxC;AACA;AACD,KATD,MASO;AACN;AACAD,MAAAA,YAAY,GAAG,KAAf;AACA;;AACD,QAAI,CAACA,YAAD,IAAiB,KAAKE,EAAL,CAAQ,CAAR,MAAetB,KAAK,CAACuB,GAA1C,EAA+C;AAC9C,YAAM,oBAAN;AACA;;AACD,QAAI,KAAKC,IAAL,CAAU,KAAKf,KAAL,GAAa,CAAvB,CAAJ,EAA+B;AAC9B,WAAKA,KAAL,GAAa,KAAKQ,eAAL,CAAqB,KAAKR,KAAL,GAAa,CAAlC,CAAb;AACA;AACD;AAED;AACD;AACA;AACA;AACA;AACA;AACA;;;AACCe,EAAAA,IAAI,CAACC,CAAD,EAAI;AACP,UAAMC,CAAC,GAAGD,CAAC,GAAG,KAAKjB,MAAL,CAAYa,MAAhB,GAAyB,CAAnC,CADO,CAC+B;;AACtC,QAAIK,CAAC,GAAG,CAAR,EAAW;AACV,YAAMC,OAAO,GAAG,KAAKC,KAAL,CAAWF,CAAX,CAAhB;AACA,aAAOC,OAAO,IAAID,CAAlB;AACA;;AACD,WAAO,IAAP;AACA;AAED;AACD;AACA;AACA;AACA;;;AACCE,EAAAA,KAAK,CAACF,CAAD,EAAI;AACR,QAAI,KAAKhB,UAAT,EAAqB;AACpB,aAAO,CAAP;AACA;;AACD,SAAK,IAAIe,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGC,CAApB,EAAuBD,CAAC,EAAxB,EAA4B;AAC3B,YAAMI,CAAC,GAAG,KAAKtB,WAAL,CAAiBuB,SAAjB,EAAV;AACAD,MAAAA,CAAC,CAACE,UAAF,GAAe,KAAKvB,MAAL,CAAYa,MAA3B;AACA,WAAKb,MAAL,CAAYwB,IAAZ,CAAiBH,CAAjB;;AACA,UAAIA,CAAC,CAACI,IAAF,KAAWjC,KAAK,CAACuB,GAArB,EAA0B;AACzB,aAAKb,UAAL,GAAkB,IAAlB;AACA,eAAOe,CAAC,GAAG,CAAX;AACA;AACD;;AACD,WAAOC,CAAP;AACA,GA9H4C,CAgI9C;;;AACCQ,EAAAA,SAAS,CAACC,KAAD,EAAQC,IAAR,EAAcC,KAAd,EAAqB;AAC7B,QAAIA,KAAK,KAAKC,SAAd,EAAyB;AACxBD,MAAAA,KAAK,GAAG,IAAR;AACA;;AACD,QAAIF,KAAK,GAAG,CAAR,IAAaC,IAAI,GAAG,CAAxB,EAA2B;AAC1B,aAAO,IAAP;AACA;;AACD,SAAKpB,QAAL;AACA,UAAMuB,MAAM,GAAG,EAAf;;AACA,QAAIH,IAAI,IAAI,KAAK5B,MAAL,CAAYa,MAAxB,EAAgC;AAC/Be,MAAAA,IAAI,GAAG,KAAK5B,MAAL,CAAYa,MAAZ,GAAqB,CAA5B;AACA;;AACD,SAAK,IAAII,CAAC,GAAGU,KAAb,EAAoBV,CAAC,GAAGW,IAAxB,EAA8BX,CAAC,EAA/B,EAAmC;AAClC,YAAMI,CAAC,GAAG,KAAKrB,MAAL,CAAYiB,CAAZ,CAAV;;AACA,UAAII,CAAC,CAACI,IAAF,KAAWjC,KAAK,CAACuB,GAArB,EAA0B;AACzB;AACA;;AACD,UAAIc,KAAK,KAAK,IAAV,IAAkBA,KAAK,CAACG,QAAN,CAAeX,CAAC,CAACI,IAAjB,CAAtB,EAA8C;AAC7CM,QAAAA,MAAM,CAACP,IAAP,CAAYH,CAAZ;AACA;AACD;;AACD,WAAOU,MAAP;AACA;;AAEDjB,EAAAA,EAAE,CAACG,CAAD,EAAI;AACL,WAAO,KAAKgB,EAAL,CAAQhB,CAAR,EAAWQ,IAAlB;AACA;;AAEDS,EAAAA,EAAE,CAACC,CAAD,EAAI;AACL,QAAI,KAAKlC,KAAL,GAAakC,CAAb,GAAiB,CAArB,EAAwB;AACvB,aAAO,IAAP;AACA;;AACD,WAAO,KAAKnC,MAAL,CAAY,KAAKC,KAAL,GAAakC,CAAzB,CAAP;AACA;;AAEDF,EAAAA,EAAE,CAACE,CAAD,EAAI;AACL,SAAK3B,QAAL;;AACA,QAAI2B,CAAC,KAAK,CAAV,EAAa;AACZ,aAAO,IAAP;AACA;;AACD,QAAIA,CAAC,GAAG,CAAR,EAAW;AACV,aAAO,KAAKD,EAAL,CAAQ,CAACC,CAAT,CAAP;AACA;;AACD,UAAMlB,CAAC,GAAG,KAAKhB,KAAL,GAAakC,CAAb,GAAiB,CAA3B;AACA,SAAKnB,IAAL,CAAUC,CAAV;;AACA,QAAIA,CAAC,IAAI,KAAKjB,MAAL,CAAYa,MAArB,EAA6B;AAAE;AAC9B;AACA,aAAO,KAAKb,MAAL,CAAY,KAAKA,MAAL,CAAYa,MAAZ,GAAqB,CAAjC,CAAP;AACA;;AACD,WAAO,KAAKb,MAAL,CAAYiB,CAAZ,CAAP;AACA;AAED;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACCR,EAAAA,eAAe,CAACQ,CAAD,EAAI;AAClB,WAAOA,CAAP;AACA;;AAEDT,EAAAA,QAAQ,GAAG;AACV,QAAI,KAAKP,KAAL,KAAe,CAAC,CAApB,EAAuB;AACtB,WAAKmC,KAAL;AACA;AACD;;AAEDA,EAAAA,KAAK,GAAG;AACP,SAAKpB,IAAL,CAAU,CAAV;AACA,SAAKf,KAAL,GAAa,KAAKQ,eAAL,CAAqB,CAArB,CAAb;AACA,GAhN4C,CAkN9C;;;AACC4B,EAAAA,cAAc,CAACtC,WAAD,EAAc;AAC3B,SAAKA,WAAL,GAAmBA,WAAnB;AACA,SAAKC,MAAL,GAAc,EAAd;AACA,SAAKC,KAAL,GAAa,CAAC,CAAd;AACA,SAAKC,UAAL,GAAkB,KAAlB;AACA;AAED;AACD;AACA;AACA;AACA;;;AACCoC,EAAAA,kBAAkB,CAACrB,CAAD,EAAIsB,OAAJ,EAAa;AAC9B,SAAKvB,IAAL,CAAUC,CAAV;;AACA,QAAIA,CAAC,IAAI,KAAKjB,MAAL,CAAYa,MAArB,EAA6B;AAC5B,aAAO,CAAC,CAAR;AACA;;AACD,QAAI2B,KAAK,GAAG,KAAKxC,MAAL,CAAYiB,CAAZ,CAAZ;;AACA,WAAOuB,KAAK,CAACD,OAAN,KAAkB,KAAKA,OAA9B,EAAuC;AACtC,UAAIC,KAAK,CAACf,IAAN,KAAejC,KAAK,CAACuB,GAAzB,EAA8B;AAC7B,eAAO,CAAC,CAAR;AACA;;AACDE,MAAAA,CAAC,IAAI,CAAL;AACA,WAAKD,IAAL,CAAUC,CAAV;AACAuB,MAAAA,KAAK,GAAG,KAAKxC,MAAL,CAAYiB,CAAZ,CAAR;AACA;;AACD,WAAOA,CAAP;AACA;AAED;AACD;AACA;AACA;AACA;;;AACCwB,EAAAA,sBAAsB,CAACxB,CAAD,EAAIsB,OAAJ,EAAa;AAClC,WAAOtB,CAAC,IAAI,CAAL,IAAU,KAAKjB,MAAL,CAAYiB,CAAZ,EAAesB,OAAf,KAA2BA,OAA5C,EAAqD;AACpDtB,MAAAA,CAAC,IAAI,CAAL;AACA;;AACD,WAAOA,CAAP;AACA;AAED;AACD;AACA;AACA;AACA;;;AACCyB,EAAAA,sBAAsB,CAACnB,UAAD,EACpBgB,OADoB,EACX;AACV,QAAIA,OAAO,KAAKT,SAAhB,EAA2B;AAC1BS,MAAAA,OAAO,GAAG,CAAC,CAAX;AACA;;AACD,SAAK/B,QAAL;;AACA,QAAIe,UAAU,GAAG,CAAb,IAAkBA,UAAU,IAAI,KAAKvB,MAAL,CAAYa,MAAhD,EAAwD;AACvD,YAAM,KAAKU,UAAL,GAAkB,aAAlB,GAAkC,KAAKvB,MAAL,CAAYa,MAA9C,GAAuD,CAA7D;AACA;;AACD,UAAM8B,aAAa,GAAG,KAAKL,kBAAL,CAAwBf,UAAU,GAAG,CAArC,EAAwC7B,KAAK,CAACkD,qBAA9C,CAAtB;AACA,UAAMC,KAAK,GAAGtB,UAAU,GAAG,CAA3B,CATU,CAUV;;AACA,UAAMuB,EAAE,GAAGH,aAAa,KAAK,CAAC,CAAnB,GAAuB,KAAK3C,MAAL,CAAYa,MAAZ,GAAqB,CAA5C,GAAgD8B,aAA3D;AACA,WAAO,KAAKI,gBAAL,CAAsBF,KAAtB,EAA6BC,EAA7B,EAAiCP,OAAjC,CAAP;AACA;AAED;AACD;AACA;AACA;AACA;;;AACCS,EAAAA,qBAAqB,CAACzB,UAAD,EACnBgB,OADmB,EACV;AACV,QAAIA,OAAO,KAAKT,SAAhB,EAA2B;AAC1BS,MAAAA,OAAO,GAAG,CAAC,CAAX;AACA;;AACD,SAAK/B,QAAL;;AACA,QAAIe,UAAU,GAAG,CAAb,IAAkBA,UAAU,IAAI,KAAKvB,MAAL,CAAYa,MAAhD,EAAwD;AACvD,YAAM,KAAKU,UAAL,GAAkB,aAAlB,GAAkC,KAAKvB,MAAL,CAAYa,MAA9C,GAAuD,CAA7D;AACA;;AACD,UAAMoC,aAAa,GAAG,KAAKR,sBAAL,CAA4BlB,UAAU,GAAG,CAAzC,EAA4C7B,KAAK,CAACkD,qBAAlD,CAAtB;;AACA,QAAIK,aAAa,KAAK1B,UAAU,GAAG,CAAnC,EAAsC;AACrC,aAAO,IAAP;AACA,KAXS,CAYV;;;AACA,UAAMsB,KAAK,GAAGI,aAAa,GAAG,CAA9B;AACA,UAAMH,EAAE,GAAGvB,UAAU,GAAG,CAAxB;AACA,WAAO,KAAKwB,gBAAL,CAAsBF,KAAtB,EAA6BC,EAA7B,EAAiCP,OAAjC,CAAP;AACA;;AAEDQ,EAAAA,gBAAgB,CAACG,IAAD,EAAOC,KAAP,EAAcZ,OAAd,EAAuB;AACtC,UAAMa,MAAM,GAAG,EAAf;;AACA,SAAK,IAAInC,CAAC,GAAGiC,IAAb,EAAmBjC,CAAC,GAAGkC,KAAK,GAAG,CAA/B,EAAkClC,CAAC,EAAnC,EAAuC;AACtC,YAAMI,CAAC,GAAG,KAAKrB,MAAL,CAAYiB,CAAZ,CAAV;;AACA,UAAIsB,OAAO,KAAK,CAAC,CAAjB,EAAoB;AACnB,YAAIlB,CAAC,CAACkB,OAAF,KAAc7C,KAAK,CAACkD,qBAAxB,EAA+C;AAC9CQ,UAAAA,MAAM,CAAC5B,IAAP,CAAYH,CAAZ;AACA;AACD,OAJD,MAIO,IAAIA,CAAC,CAACkB,OAAF,KAAcA,OAAlB,EAA2B;AACjCa,QAAAA,MAAM,CAAC5B,IAAP,CAAYH,CAAZ;AACA;AACD;;AACD,QAAI+B,MAAM,CAACvC,MAAP,KAAkB,CAAtB,EAAyB;AACxB,aAAO,IAAP;AACA;;AACD,WAAOuC,MAAP;AACA;;AAEDC,EAAAA,aAAa,GAAG;AACf,WAAO,KAAKtD,WAAL,CAAiBsD,aAAjB,EAAP;AACA,GA7T4C,CA+T9C;;;AACCC,EAAAA,OAAO,CAACC,QAAD,EAAW;AACjB,SAAK/C,QAAL;AACA,SAAKgD,IAAL;;AACA,QAAID,QAAQ,KAAKzB,SAAb,IAA0ByB,QAAQ,KAAK,IAA3C,EAAiD;AAChDA,MAAAA,QAAQ,GAAG,IAAI5D,QAAJ,CAAa,CAAb,EAAgB,KAAKK,MAAL,CAAYa,MAAZ,GAAqB,CAArC,CAAX;AACA;;AACD,QAAIc,KAAK,GAAG4B,QAAQ,CAAC5B,KAArB;;AACA,QAAIA,KAAK,YAAYnC,KAArB,EAA4B;AAC3BmC,MAAAA,KAAK,GAAGA,KAAK,CAACJ,UAAd;AACA;;AACD,QAAIK,IAAI,GAAG2B,QAAQ,CAAC3B,IAApB;;AACA,QAAIA,IAAI,YAAYpC,KAApB,EAA2B;AAC1BoC,MAAAA,IAAI,GAAGA,IAAI,CAACL,UAAZ;AACA;;AACD,QAAII,KAAK,KAAK,IAAV,IAAkBC,IAAI,KAAK,IAA3B,IAAmCD,KAAK,GAAG,CAA3C,IAAgDC,IAAI,GAAG,CAA3D,EAA8D;AAC7D,aAAO,EAAP;AACA;;AACD,QAAIA,IAAI,IAAI,KAAK5B,MAAL,CAAYa,MAAxB,EAAgC;AAC/Be,MAAAA,IAAI,GAAG,KAAK5B,MAAL,CAAYa,MAAZ,GAAqB,CAA5B;AACA;;AACD,QAAI4C,CAAC,GAAG,EAAR;;AACA,SAAK,IAAIxC,CAAC,GAAGU,KAAb,EAAoBV,CAAC,GAAGW,IAAI,GAAG,CAA/B,EAAkCX,CAAC,EAAnC,EAAuC;AACtC,YAAMI,CAAC,GAAG,KAAKrB,MAAL,CAAYiB,CAAZ,CAAV;;AACA,UAAII,CAAC,CAACI,IAAF,KAAWjC,KAAK,CAACuB,GAArB,EAA0B;AACzB;AACA;;AACD0C,MAAAA,CAAC,GAAGA,CAAC,GAAGpC,CAAC,CAACqC,IAAV;AACA;;AACD,WAAOD,CAAP;AACA,GA7V4C,CA+V9C;;;AACCD,EAAAA,IAAI,GAAG;AACN,SAAKhD,QAAL;;AACA,WAAO,KAAKY,KAAL,CAAW,IAAX,MAAqB,IAA5B,EAAkC;AACjC;AACA;AACD;;AArW4C;;AAyW9CuC,MAAM,CAACC,OAAP,GAAiB/D,mBAAjB","sourcesContent":["/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nconst {Token} = require('./Token');\nconst Lexer = require('./Lexer');\nconst {Interval} = require('./IntervalSet');\n\n// this is just to keep meaningful parameter types to Parser\nclass TokenStream {}\n\n/**\n * This implementation of {@link TokenStream} loads tokens from a\n * {@link TokenSource} on-demand, and places the tokens in a buffer to provide\n * access to any previous token by index.\n *\n * <p>\n * This token stream ignores the value of {@link Token//getChannel}. If your\n * parser requires the token stream filter tokens to only those on a particular\n * channel, such as {@link Token//DEFAULT_CHANNEL} or\n * {@link Token//HIDDEN_CHANNEL}, use a filtering token stream such a\n * {@link CommonTokenStream}.</p>\n */\nclass BufferedTokenStream extends TokenStream {\n\tconstructor(tokenSource) {\n\n\t\tsuper();\n\t\t// The {@link TokenSource} from which tokens for this stream are fetched.\n\t\tthis.tokenSource = tokenSource;\n\t\t/**\n\t\t * A collection of all tokens fetched from the token source. The list is\n\t\t * considered a complete view of the input once {@link //fetchedEOF} is set\n\t\t * to {@code true}.\n\t\t */\n\t\tthis.tokens = [];\n\n\t\t/**\n\t\t * The index into {@link //tokens} of the current token (next token to\n\t\t * {@link //consume}). {@link //tokens}{@code [}{@link //p}{@code ]} should\n\t\t * be\n\t\t * {@link //LT LT(1)}.\n\t\t *\n\t\t * <p>This field is set to -1 when the stream is first constructed or when\n\t\t * {@link //setTokenSource} is called, indicating that the first token has\n\t\t * not yet been fetched from the token source. For additional information,\n\t\t * see the documentation of {@link IntStream} for a description of\n\t\t * Initializing Methods.</p>\n\t\t */\n\t\tthis.index = -1;\n\n\t\t/**\n\t\t * Indicates whether the {@link Token//EOF} token has been fetched from\n\t\t * {@link //tokenSource} and added to {@link //tokens}. This field improves\n\t\t * performance for the following cases:\n\t\t *\n\t\t * <ul>\n\t\t * <li>{@link //consume}: The lookahead check in {@link //consume} to\n\t\t * prevent\n\t\t * consuming the EOF symbol is optimized by checking the values of\n\t\t * {@link //fetchedEOF} and {@link //p} instead of calling {@link\n\t\t * //LA}.</li>\n\t\t * <li>{@link //fetch}: The check to prevent adding multiple EOF symbols\n\t\t * into\n\t\t * {@link //tokens} is trivial with this field.</li>\n\t\t * <ul>\n\t\t */\n\t\tthis.fetchedEOF = false;\n\t}\n\n\tmark() {\n\t\treturn 0;\n\t}\n\n\trelease(marker) {\n\t\t// no resources to release\n\t}\n\n\treset() {\n\t\tthis.seek(0);\n\t}\n\n\tseek(index) {\n\t\tthis.lazyInit();\n\t\tthis.index = this.adjustSeekIndex(index);\n\t}\n\n\tget(index) {\n\t\tthis.lazyInit();\n\t\treturn this.tokens[index];\n\t}\n\n\tconsume() {\n\t\tlet skipEofCheck = false;\n\t\tif (this.index >= 0) {\n\t\t\tif (this.fetchedEOF) {\n\t\t\t\t// the last token in tokens is EOF. skip check if p indexes any\n\t\t\t\t// fetched token except the last.\n\t\t\t\tskipEofCheck = this.index < this.tokens.length - 1;\n\t\t\t} else {\n\t\t\t\t// no EOF token in tokens. skip check if p indexes a fetched token.\n\t\t\t\tskipEofCheck = this.index < this.tokens.length;\n\t\t\t}\n\t\t} else {\n\t\t\t// not yet initialized\n\t\t\tskipEofCheck = false;\n\t\t}\n\t\tif (!skipEofCheck && this.LA(1) === Token.EOF) {\n\t\t\tthrow \"cannot consume EOF\";\n\t\t}\n\t\tif (this.sync(this.index + 1)) {\n\t\t\tthis.index = this.adjustSeekIndex(this.index + 1);\n\t\t}\n\t}\n\n\t/**\n\t * Make sure index {@code i} in tokens has a token.\n\t *\n\t * @return {Boolean} {@code true} if a token is located at index {@code i}, otherwise\n\t * {@code false}.\n\t * @see //get(int i)\n\t */\n\tsync(i) {\n\t\tconst n = i - this.tokens.length + 1; // how many more elements we need?\n\t\tif (n > 0) {\n\t\t\tconst fetched = this.fetch(n);\n\t\t\treturn fetched >= n;\n\t\t}\n\t\treturn true;\n\t}\n\n\t/**\n\t * Add {@code n} elements to buffer.\n\t *\n\t * @return {Number} The actual number of elements added to the buffer.\n\t */\n\tfetch(n) {\n\t\tif (this.fetchedEOF) {\n\t\t\treturn 0;\n\t\t}\n\t\tfor (let i = 0; i < n; i++) {\n\t\t\tconst t = this.tokenSource.nextToken();\n\t\t\tt.tokenIndex = this.tokens.length;\n\t\t\tthis.tokens.push(t);\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tthis.fetchedEOF = true;\n\t\t\t\treturn i + 1;\n\t\t\t}\n\t\t}\n\t\treturn n;\n\t}\n\n// Get all tokens from start..stop inclusively///\n\tgetTokens(start, stop, types) {\n\t\tif (types === undefined) {\n\t\t\ttypes = null;\n\t\t}\n\t\tif (start < 0 || stop < 0) {\n\t\t\treturn null;\n\t\t}\n\t\tthis.lazyInit();\n\t\tconst subset = [];\n\t\tif (stop >= this.tokens.length) {\n\t\t\tstop = this.tokens.length - 1;\n\t\t}\n\t\tfor (let i = start; i < stop; i++) {\n\t\t\tconst t = this.tokens[i];\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (types === null || types.contains(t.type)) {\n\t\t\t\tsubset.push(t);\n\t\t\t}\n\t\t}\n\t\treturn subset;\n\t}\n\n\tLA(i) {\n\t\treturn this.LT(i).type;\n\t}\n\n\tLB(k) {\n\t\tif (this.index - k < 0) {\n\t\t\treturn null;\n\t\t}\n\t\treturn this.tokens[this.index - k];\n\t}\n\n\tLT(k) {\n\t\tthis.lazyInit();\n\t\tif (k === 0) {\n\t\t\treturn null;\n\t\t}\n\t\tif (k < 0) {\n\t\t\treturn this.LB(-k);\n\t\t}\n\t\tconst i = this.index + k - 1;\n\t\tthis.sync(i);\n\t\tif (i >= this.tokens.length) { // return EOF token\n\t\t\t// EOF must be last token\n\t\t\treturn this.tokens[this.tokens.length - 1];\n\t\t}\n\t\treturn this.tokens[i];\n\t}\n\n\t/**\n\t * Allowed derived classes to modify the behavior of operations which change\n\t * the current stream position by adjusting the target token index of a seek\n\t * operation. The default implementation simply returns {@code i}. If an\n\t * exception is thrown in this method, the current stream index should not be\n\t * changed.\n\t *\n\t * <p>For example, {@link CommonTokenStream} overrides this method to ensure\n\t * that\n\t * the seek target is always an on-channel token.</p>\n\t *\n\t * @param {Number} i The target token index.\n\t * @return {Number} The adjusted target token index.\n\t */\n\tadjustSeekIndex(i) {\n\t\treturn i;\n\t}\n\n\tlazyInit() {\n\t\tif (this.index === -1) {\n\t\t\tthis.setup();\n\t\t}\n\t}\n\n\tsetup() {\n\t\tthis.sync(0);\n\t\tthis.index = this.adjustSeekIndex(0);\n\t}\n\n// Reset this token stream by setting its token source.///\n\tsetTokenSource(tokenSource) {\n\t\tthis.tokenSource = tokenSource;\n\t\tthis.tokens = [];\n\t\tthis.index = -1;\n\t\tthis.fetchedEOF = false;\n\t}\n\n\t/**\n\t * Given a starting index, return the index of the next token on channel.\n\t * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n\t * on channel between i and EOF.\n\t */\n\tnextTokenOnChannel(i, channel) {\n\t\tthis.sync(i);\n\t\tif (i >= this.tokens.length) {\n\t\t\treturn -1;\n\t\t}\n\t\tlet token = this.tokens[i];\n\t\twhile (token.channel !== this.channel) {\n\t\t\tif (token.type === Token.EOF) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\ti += 1;\n\t\t\tthis.sync(i);\n\t\t\ttoken = this.tokens[i];\n\t\t}\n\t\treturn i;\n\t}\n\n\t/**\n\t * Given a starting index, return the index of the previous token on channel.\n\t * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n\t * on channel between i and 0.\n\t */\n\tpreviousTokenOnChannel(i, channel) {\n\t\twhile (i >= 0 && this.tokens[i].channel !== channel) {\n\t\t\ti -= 1;\n\t\t}\n\t\treturn i;\n\t}\n\n\t/**\n\t * Collect all tokens on specified channel to the right of\n\t * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or\n\t * EOF. If channel is -1, find any non default channel token.\n\t */\n\tgetHiddenTokensToRight(tokenIndex,\n\t\t\tchannel) {\n\t\tif (channel === undefined) {\n\t\t\tchannel = -1;\n\t\t}\n\t\tthis.lazyInit();\n\t\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\t\tthrow \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n\t\t}\n\t\tconst nextOnChannel = this.nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n\t\tconst from_ = tokenIndex + 1;\n\t\t// if none onchannel to right, nextOnChannel=-1 so set to = last token\n\t\tconst to = nextOnChannel === -1 ? this.tokens.length - 1 : nextOnChannel;\n\t\treturn this.filterForChannel(from_, to, channel);\n\t}\n\n\t/**\n\t * Collect all tokens on specified channel to the left of\n\t * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.\n\t * If channel is -1, find any non default channel token.\n\t */\n\tgetHiddenTokensToLeft(tokenIndex,\n\t\t\tchannel) {\n\t\tif (channel === undefined) {\n\t\t\tchannel = -1;\n\t\t}\n\t\tthis.lazyInit();\n\t\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\t\tthrow \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n\t\t}\n\t\tconst prevOnChannel = this.previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n\t\tif (prevOnChannel === tokenIndex - 1) {\n\t\t\treturn null;\n\t\t}\n\t\t// if none on channel to left, prevOnChannel=-1 then from=0\n\t\tconst from_ = prevOnChannel + 1;\n\t\tconst to = tokenIndex - 1;\n\t\treturn this.filterForChannel(from_, to, channel);\n\t}\n\n\tfilterForChannel(left, right, channel) {\n\t\tconst hidden = [];\n\t\tfor (let i = left; i < right + 1; i++) {\n\t\t\tconst t = this.tokens[i];\n\t\t\tif (channel === -1) {\n\t\t\t\tif (t.channel !== Lexer.DEFAULT_TOKEN_CHANNEL) {\n\t\t\t\t\thidden.push(t);\n\t\t\t\t}\n\t\t\t} else if (t.channel === channel) {\n\t\t\t\thidden.push(t);\n\t\t\t}\n\t\t}\n\t\tif (hidden.length === 0) {\n\t\t\treturn null;\n\t\t}\n\t\treturn hidden;\n\t}\n\n\tgetSourceName() {\n\t\treturn this.tokenSource.getSourceName();\n\t}\n\n// Get the text of all tokens in this buffer.///\n\tgetText(interval) {\n\t\tthis.lazyInit();\n\t\tthis.fill();\n\t\tif (interval === undefined || interval === null) {\n\t\t\tinterval = new Interval(0, this.tokens.length - 1);\n\t\t}\n\t\tlet start = interval.start;\n\t\tif (start instanceof Token) {\n\t\t\tstart = start.tokenIndex;\n\t\t}\n\t\tlet stop = interval.stop;\n\t\tif (stop instanceof Token) {\n\t\t\tstop = stop.tokenIndex;\n\t\t}\n\t\tif (start === null || stop === null || start < 0 || stop < 0) {\n\t\t\treturn \"\";\n\t\t}\n\t\tif (stop >= this.tokens.length) {\n\t\t\tstop = this.tokens.length - 1;\n\t\t}\n\t\tlet s = \"\";\n\t\tfor (let i = start; i < stop + 1; i++) {\n\t\t\tconst t = this.tokens[i];\n\t\t\tif (t.type === Token.EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ts = s + t.text;\n\t\t}\n\t\treturn s;\n\t}\n\n// Get all tokens from lexer until EOF///\n\tfill() {\n\t\tthis.lazyInit();\n\t\twhile (this.fetch(1000) === 1000) {\n\t\t\tcontinue;\n\t\t}\n\t}\n}\n\n\nmodule.exports = BufferedTokenStream;\n"]},"metadata":{},"sourceType":"script"}